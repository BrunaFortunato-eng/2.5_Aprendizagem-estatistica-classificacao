{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Classificadores Lineares\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Classificadores KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Classificadores Naive Nayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Classificadores Arvores de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy.io import arff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Multiplas Classes\n",
    "* A resposta (y) ́e umas das multiplas classes possıveis\n",
    "\n",
    "### Usando base Iris para teste\n",
    "#### Variáveis independentes:\n",
    "\n",
    "* Largura de pétala\n",
    "* altura de pétala\n",
    "* Largura de sépala\n",
    "* altura de sépala\n",
    "\n",
    "#### Variável a ser predita:\n",
    "* Predizer: species (Nesse dataset 3 possíveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para datasets com muitas variáveis independentes é possível eliminar apenas o label usando drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "X = df.drop(['species'], axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print( df['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "\n",
    "* Se a opção escolhida for \"ovr\", um problema binário é montado para cada rótulo. \n",
    "* Para \"multinomial\", a perda minimizada é o ajuste de perda multinomial em toda a distribuição de probabilidade, mesmo se houber apenas duas classes\n",
    "* \"Multinomial\" fica indisponível quando solver = 'liblinear'. \n",
    "'Auto' seleciona 'ovr' se os dados são binários ou se solver = 'liblinear' caso contrário, seleciona 'multinomial'.\n",
    "\n",
    "ref: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "* Algoritmo a ser usado na otimização.\n",
    "\n",
    "* Para conjuntos de dados pequenos, 'liblinear' é uma boa opção, enquanto 'sag' e 'saga' são mais rápidos para conjuntos grandes de dados\n",
    "\n",
    "* Apenas 'newton-cg', 'sag', 'saga' e 'lbfgs' lidam com a perda multinomial; \n",
    "\n",
    "* \"Liblinear\" é limitado a esquemas de um contra o resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd_clf = SGDClassifier(random_state=42)\n",
    "#sgd_clf = LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "# 'newton-cg', 'sag', 'saga' e 'lbfgs\n",
    "sgd_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A matriz de confusão gerada para datasets com variável alvo possuindo mais de uma classe, é quadrada sendo seu tamanho igual a quantidade de classes\n",
    "\n",
    "### Para esse caso três espécies, portanto matriz quadrada 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretação\n",
    "* As classes setosa e versicolor não tiverem erros (precision 1)\n",
    "* A classe virginica houve 5 erros (precision 0.69)\n",
    "* versicolor possui recall 0.71 => TP / TP+FN (12 / 12 + 5) => 0.7\n",
    "* nesse caso, instancias da classe virginica todos foram confundidos com versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando múltiplas classes com KNN, Arvore e Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de Decição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       0.83      1.00      0.91         5\n",
      "   virginica       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.94      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador um contra todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador aos pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício Mnist\n",
    "* 786 colunas de características\n",
    "* coluna label identifica o número\n",
    "* crie um dataframe para representar a base mnist\n",
    "* crie um classificador de multiplas classes (usando a coluna label) como alvo\n",
    "* interprete o resultado\n",
    "* Qual valor (entre 0 a 9) o classificador teve mais sucesso em identificar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       980\n",
      "           1       0.95      0.96      0.95      1135\n",
      "           2       0.86      0.85      0.86      1032\n",
      "           3       0.83      0.84      0.84      1010\n",
      "           4       0.88      0.87      0.87       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.90      0.88      0.89       958\n",
      "           7       0.90      0.91      0.90      1028\n",
      "           8       0.83      0.81      0.82       974\n",
      "           9       0.85      0.86      0.86      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Resolva o exercicio aqui...\n",
    "df_train = pd.read_csv('mnist-in-csv/mnist_train.csv')\n",
    "df.describe()\n",
    "\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "df_test = pd.read_csv('mnist-in-csv/mnist_test.csv')\n",
    "\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# O classificador obteve maior sucesso em identificar o numero 1 e maior dificuldade em classificar o numero 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       980\n",
      "           1       0.94      1.00      0.97      1135\n",
      "           2       0.98      0.95      0.97      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.97      0.96      0.97       982\n",
      "           5       0.97      0.97      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.93      0.96       974\n",
      "           9       0.96      0.95      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8, n_jobs=12)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.453933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.889270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042472</td>\n",
       "      <td>3.956189</td>\n",
       "      <td>2.839845</td>\n",
       "      <td>1.686770</td>\n",
       "      <td>1.678283</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
       "count  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
       "mean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
       "count  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.200433      0.088867   \n",
       "std        0.0      0.0      0.0  ...      6.042472      3.956189   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "              28x21         28x22         28x23       28x24    28x25    28x26  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \n",
       "mean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \n",
       "std        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "max      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n",
       "\n",
       "         28x27    28x28  \n",
       "count  60000.0  60000.0  \n",
       "mean       0.0      0.0  \n",
       "std        0.0      0.0  \n",
       "min        0.0      0.0  \n",
       "25%        0.0      0.0  \n",
       "50%        0.0      0.0  \n",
       "75%        0.0      0.0  \n",
       "max        0.0      0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mnist-in-csv/mnist_train.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação entre variável indepentes X e variáveis alvo Y \n",
    "* Mais de uma classe possível para cada instância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  método scipy.io.arff.loadarff \n",
    "* Método para leitura de arquivos no formato Attribute-Relation File Format (ARFF)\n",
    "* Fonte de bases de dados multilabel no formato arff : https://github.com/tsoumakas/mulan/tree/master/data/multi-label\n",
    "* (yeast): base de dados para estudos de proteínas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yeast-train.arff.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9313b1a9eedc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yeast-train.arff.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amb1/lib/python3.7/site-packages/scipy/io/arff/arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yeast-train.arff.txt'"
     ]
    }
   ],
   "source": [
    "data, meta = scipy.io.arff.loadarff('yeast-train.arff.txt')\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação de dados\n",
    "* Codificação de variáveis categóricas\n",
    "* Separação em Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "Y = df[['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y['class1'] = le.fit_transform(Y['Class1'])\n",
    "Y['class2'] = le.fit_transform(Y['Class2'])\n",
    "Y['class3'] = le.fit_transform(Y['Class3'])\n",
    "Y['class4'] = le.fit_transform(Y['Class4'])\n",
    "Y['class5'] = le.fit_transform(Y['Class5'])\n",
    "Y['class6'] = le.fit_transform(Y['Class6'])\n",
    "Y['class7'] = le.fit_transform(Y['Class7'])\n",
    "Y['class8'] = le.fit_transform(Y['Class8'])\n",
    "Y['class9'] = le.fit_transform(Y['Class9'])\n",
    "Y['class10'] = le.fit_transform(Y['Class10'])\n",
    "Y['class11'] = le.fit_transform(Y['Class11'])\n",
    "Y['class12'] = le.fit_transform(Y['Class12'])\n",
    "Y['class13'] = le.fit_transform(Y['Class13'])\n",
    "Y['class14'] = le.fit_transform(Y['Class14'])\n",
    "\n",
    "Y = Y.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando regressão logística a dados multi-classe\n",
    "* Método apresenta erro de mal-formato de Y, indicando que não aceita múltiplas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "y_pred = sgd_clf.predict(X_train)\n",
    "print(classification_report(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerando apenas uma classe como variável a ser predita\n",
    "* Regressão Logística funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = Y[['class1']]\n",
    "\n",
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "#sgd_clf = LogisticRegression()\n",
    "sgd_clf.fit(X, YY)\n",
    "y_pred = sgd_clf.predict(X)\n",
    "print(classification_report(YY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No scikit-learn alguns métodos aceitam dataset multiclasse: como o DecisionTreeClassifier por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outro exemplo de método que aceita múltiplas classes por instância:\n",
    "* import sklearn.ensemble.ExtraTreesClassifier\n",
    "* import sklearn.neighbors.KNeighborsClassifier\n",
    "* import sklearn.neighbors.RadiusNeighborsClassifier\n",
    "* import sklearn.ensemble.RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando modelos:\n",
    "\n",
    "* Micro average (média do total de verdadeiros positivos, falsos negativos e falsos positivos) para múltiplas classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício\n",
    "### Dataset de Paisagens: \n",
    "\n",
    "* 294 atributos para descrever a imagem \n",
    "* 6 colunas para predição: Beach Sunset FallFoliage Field Mountain Urban\n",
    "\n",
    "Arquivo: scene.arff\n",
    "Fonte: https://datahub.io/machine-learning/scene\n",
    "\n",
    "Faça um classificador multiclassse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.699053</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.247298</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.767255</td>\n",
       "      <td>0.761053</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>0.760633</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.793984</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>0.734361</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.938563</td>\n",
       "      <td>0.949260</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.953460</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2402</td>\n",
       "      <td>0.875782</td>\n",
       "      <td>0.901653</td>\n",
       "      <td>0.926227</td>\n",
       "      <td>0.721366</td>\n",
       "      <td>0.795826</td>\n",
       "      <td>0.867642</td>\n",
       "      <td>0.794125</td>\n",
       "      <td>0.899067</td>\n",
       "      <td>0.908963</td>\n",
       "      <td>0.895336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215147</td>\n",
       "      <td>0.279607</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2403</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>0.669877</td>\n",
       "      <td>0.692338</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.727374</td>\n",
       "      <td>0.750354</td>\n",
       "      <td>0.684372</td>\n",
       "      <td>0.718770</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>0.730645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217201</td>\n",
       "      <td>0.199491</td>\n",
       "      <td>0.048747</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2404</td>\n",
       "      <td>0.952281</td>\n",
       "      <td>0.944987</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.836604</td>\n",
       "      <td>0.875916</td>\n",
       "      <td>0.957034</td>\n",
       "      <td>0.953938</td>\n",
       "      <td>0.967956</td>\n",
       "      <td>0.819636</td>\n",
       "      <td>0.707311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2405</td>\n",
       "      <td>0.883990</td>\n",
       "      <td>0.899004</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.904298</td>\n",
       "      <td>0.846402</td>\n",
       "      <td>0.858145</td>\n",
       "      <td>0.851362</td>\n",
       "      <td>0.852472</td>\n",
       "      <td>0.876665</td>\n",
       "      <td>0.908187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239041</td>\n",
       "      <td>0.256158</td>\n",
       "      <td>0.226332</td>\n",
       "      <td>0.223070</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2406</td>\n",
       "      <td>0.974915</td>\n",
       "      <td>0.866425</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>0.936140</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.935087</td>\n",
       "      <td>0.930597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806074</td>\n",
       "      <td>0.717955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.025059</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2407 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "0     0.646467  0.666435  0.685047  0.699053  0.652746  0.407864  0.150309   \n",
       "1     0.770156  0.767255  0.761053  0.745630  0.742231  0.688086  0.708416   \n",
       "2     0.793984  0.772096  0.761820  0.762213  0.740569  0.734361  0.722677   \n",
       "3     0.938563  0.949260  0.955621  0.966743  0.968649  0.869619  0.696925   \n",
       "4     0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2402  0.875782  0.901653  0.926227  0.721366  0.795826  0.867642  0.794125   \n",
       "2403  0.657706  0.669877  0.692338  0.713920  0.727374  0.750354  0.684372   \n",
       "2404  0.952281  0.944987  0.905556  0.836604  0.875916  0.957034  0.953938   \n",
       "2405  0.883990  0.899004  0.901019  0.904298  0.846402  0.858145  0.851362   \n",
       "2406  0.974915  0.866425  0.818144  0.936140  0.938583  0.935087  0.930597   \n",
       "\n",
       "         attr8     attr9    attr10  ...   attr291   attr292   attr293  \\\n",
       "0     0.535193  0.555689  0.580782  ...  0.157332  0.247298  0.014025   \n",
       "1     0.757351  0.760633  0.740314  ...  0.251454  0.137833  0.082672   \n",
       "2     0.849128  0.839607  0.812746  ...  0.017166  0.051125  0.112506   \n",
       "3     0.953460  0.959631  0.966320  ...  0.019267  0.031290  0.049780   \n",
       "4     0.562266  0.588592  0.584449  ...  0.198151  0.238796  0.164270   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2402  0.899067  0.908963  0.895336  ...  0.215147  0.279607  0.254413   \n",
       "2403  0.718770  0.719916  0.730645  ...  0.217201  0.199491  0.048747   \n",
       "2404  0.967956  0.819636  0.707311  ...  0.028002  0.031900  0.017547   \n",
       "2405  0.852472  0.876665  0.908187  ...  0.239041  0.256158  0.226332   \n",
       "2406  1.000000  0.806074  0.717955  ...  0.073742  0.005131  0.025059   \n",
       "\n",
       "       attr294  Beach  Sunset  FallFoliage  Field  Mountain  Urban  \n",
       "0     0.029709   b'1'    b'0'         b'0'   b'0'      b'1'   b'0'  \n",
       "1     0.036320   b'1'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2     0.083924   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "3     0.090959   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "4     0.184290   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "...        ...    ...     ...          ...    ...       ...    ...  \n",
       "2402  0.134350   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2403  0.041638   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2404  0.019734   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2405  0.223070   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2406  0.004033   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "\n",
       "[2407 rows x 300 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, meta = scipy.io.arff.loadarff('scene_arff.arff')\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Beach','Sunset','FallFoliage','Mountain','Urban'], axis=1)\n",
    "Y = df[['Beach','Sunset','FallFoliage','Mountain','Urban']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y['Beach'] = le.fit_transform(Y['Beach'])\n",
    "Y['Sunset'] = le.fit_transform(Y['Sunset'])\n",
    "Y['FallFoliage'] = le.fit_transform(Y['FallFoliage'])\n",
    "Y['Mountain'] = le.fit_transform(Y['Mountain'])\n",
    "Y['Urban'] = le.fit_transform(Y['Urban'])\n",
    "\n",
    "#Y = Y.drop(['Beach','Sunset','FallFoliage','Mountain','Urban'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr286</th>\n",
       "      <th>attr287</th>\n",
       "      <th>attr288</th>\n",
       "      <th>attr289</th>\n",
       "      <th>attr290</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.617068</td>\n",
       "      <td>0.628798</td>\n",
       "      <td>0.646405</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>0.685973</td>\n",
       "      <td>0.688777</td>\n",
       "      <td>0.693232</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.725616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>0.248967</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.362372</td>\n",
       "      <td>0.435334</td>\n",
       "      <td>0.525943</td>\n",
       "      <td>0.578541</td>\n",
       "      <td>0.558132</td>\n",
       "      <td>0.294879</td>\n",
       "      <td>0.349496</td>\n",
       "      <td>0.431823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104691</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.053322</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>0.222781</td>\n",
       "      <td>0.163611</td>\n",
       "      <td>0.109735</td>\n",
       "      <td>0.178380</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119</td>\n",
       "      <td>0.600747</td>\n",
       "      <td>0.633892</td>\n",
       "      <td>0.655035</td>\n",
       "      <td>0.694504</td>\n",
       "      <td>0.710510</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>0.654365</td>\n",
       "      <td>0.630110</td>\n",
       "      <td>0.688345</td>\n",
       "      <td>0.721997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.059548</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2144</td>\n",
       "      <td>0.827845</td>\n",
       "      <td>0.828814</td>\n",
       "      <td>0.829645</td>\n",
       "      <td>0.826850</td>\n",
       "      <td>0.841996</td>\n",
       "      <td>0.824409</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.855572</td>\n",
       "      <td>0.856029</td>\n",
       "      <td>0.862680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229602</td>\n",
       "      <td>0.271889</td>\n",
       "      <td>0.184754</td>\n",
       "      <td>0.133429</td>\n",
       "      <td>0.281802</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.152006</td>\n",
       "      <td>0.228537</td>\n",
       "      <td>0.186173</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.206207</td>\n",
       "      <td>0.212935</td>\n",
       "      <td>0.263953</td>\n",
       "      <td>0.410147</td>\n",
       "      <td>0.340976</td>\n",
       "      <td>0.292023</td>\n",
       "      <td>0.253608</td>\n",
       "      <td>0.213829</td>\n",
       "      <td>0.298926</td>\n",
       "      <td>0.418848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290775</td>\n",
       "      <td>0.301840</td>\n",
       "      <td>0.679944</td>\n",
       "      <td>0.545042</td>\n",
       "      <td>0.663586</td>\n",
       "      <td>0.229375</td>\n",
       "      <td>0.589030</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>0.324504</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1877</td>\n",
       "      <td>0.380992</td>\n",
       "      <td>0.449990</td>\n",
       "      <td>0.504832</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.603147</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>0.605494</td>\n",
       "      <td>0.429513</td>\n",
       "      <td>0.484929</td>\n",
       "      <td>0.481959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760621</td>\n",
       "      <td>0.618755</td>\n",
       "      <td>0.131865</td>\n",
       "      <td>0.319508</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.337625</td>\n",
       "      <td>0.272396</td>\n",
       "      <td>0.444576</td>\n",
       "      <td>0.475472</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.167709</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.218534</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.440256</td>\n",
       "      <td>0.489002</td>\n",
       "      <td>0.534474</td>\n",
       "      <td>0.553284</td>\n",
       "      <td>0.567649</td>\n",
       "      <td>0.566810</td>\n",
       "      <td>0.557698</td>\n",
       "      <td>0.671836</td>\n",
       "      <td>0.712883</td>\n",
       "      <td>0.735640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250637</td>\n",
       "      <td>0.126859</td>\n",
       "      <td>0.269230</td>\n",
       "      <td>0.137096</td>\n",
       "      <td>0.137109</td>\n",
       "      <td>0.178980</td>\n",
       "      <td>0.333771</td>\n",
       "      <td>0.163273</td>\n",
       "      <td>0.124642</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>0.642848</td>\n",
       "      <td>0.640235</td>\n",
       "      <td>0.651147</td>\n",
       "      <td>0.648433</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.615422</td>\n",
       "      <td>0.597133</td>\n",
       "      <td>0.697602</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.641794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234771</td>\n",
       "      <td>0.049793</td>\n",
       "      <td>0.057771</td>\n",
       "      <td>0.125030</td>\n",
       "      <td>0.126992</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.057262</td>\n",
       "      <td>0.269526</td>\n",
       "      <td>0.357331</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0.977766</td>\n",
       "      <td>0.980804</td>\n",
       "      <td>0.974911</td>\n",
       "      <td>0.941395</td>\n",
       "      <td>0.752848</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>0.581409</td>\n",
       "      <td>0.719703</td>\n",
       "      <td>0.727587</td>\n",
       "      <td>0.723511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070820</td>\n",
       "      <td>0.125821</td>\n",
       "      <td>0.068049</td>\n",
       "      <td>0.103223</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.076434</td>\n",
       "      <td>0.093171</td>\n",
       "      <td>0.073898</td>\n",
       "      <td>0.081726</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2166 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "2025  0.617068  0.628798  0.646405  0.665450  0.685973  0.688777  0.693232   \n",
       "1498  0.248967  0.297908  0.362372  0.435334  0.525943  0.578541  0.558132   \n",
       "1119  0.600747  0.633892  0.655035  0.694504  0.710510  0.689767  0.654365   \n",
       "2144  0.827845  0.828814  0.829645  0.826850  0.841996  0.824409  0.793373   \n",
       "1134  0.206207  0.212935  0.263953  0.410147  0.340976  0.292023  0.253608   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1877  0.380992  0.449990  0.504832  0.557839  0.603147  0.613415  0.605494   \n",
       "4     0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       "17    0.440256  0.489002  0.534474  0.553284  0.567649  0.566810  0.557698   \n",
       "1323  0.642848  0.640235  0.651147  0.648433  0.630755  0.615422  0.597133   \n",
       "696   0.977766  0.980804  0.974911  0.941395  0.752848  0.603767  0.581409   \n",
       "\n",
       "         attr8     attr9    attr10  ...   attr286   attr287   attr288  \\\n",
       "2025  0.702317  0.718660  0.725616  ...  0.000782  0.001316  0.003359   \n",
       "1498  0.294879  0.349496  0.431823  ...  0.104691  0.067472  0.021799   \n",
       "1119  0.630110  0.688345  0.721997  ...  0.016305  0.016987  0.059548   \n",
       "2144  0.855572  0.856029  0.862680  ...  0.229602  0.271889  0.184754   \n",
       "1134  0.213829  0.298926  0.418848  ...  0.290775  0.301840  0.679944   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1877  0.429513  0.484929  0.481959  ...  0.760621  0.618755  0.131865   \n",
       "4     0.562266  0.588592  0.584449  ...  0.023177  0.129994  0.167709   \n",
       "17    0.671836  0.712883  0.735640  ...  0.250637  0.126859  0.269230   \n",
       "1323  0.697602  0.581560  0.641794  ...  0.234771  0.049793  0.057771   \n",
       "696   0.719703  0.727587  0.723511  ...  0.070820  0.125821  0.068049   \n",
       "\n",
       "       attr289   attr290   attr291   attr292   attr293   attr294  Field  \n",
       "2025  0.006104  0.007180  0.022375  0.010380  0.005132  0.002450   b'0'  \n",
       "1498  0.053322  0.117203  0.222781  0.163611  0.109735  0.178380   b'0'  \n",
       "1119  0.030031  0.024171  0.019183  0.020275  0.014107  0.020303   b'0'  \n",
       "2144  0.133429  0.281802  0.117910  0.152006  0.228537  0.186173   b'0'  \n",
       "1134  0.545042  0.663586  0.229375  0.589030  0.638963  0.324504   b'0'  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "1877  0.319508  0.320980  0.337625  0.272396  0.444576  0.475472   b'1'  \n",
       "4     0.226580  0.218534  0.198151  0.238796  0.164270  0.184290   b'0'  \n",
       "17    0.137096  0.137109  0.178980  0.333771  0.163273  0.124642   b'0'  \n",
       "1323  0.125030  0.126992  0.020646  0.057262  0.269526  0.357331   b'0'  \n",
       "696   0.103223  0.063448  0.076434  0.093171  0.073898  0.081726   b'1'  \n",
       "\n",
       "[2166 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2166 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Beach  Sunset  FallFoliage  Mountain  Urban\n",
       "2025      0       0            0         1      0\n",
       "1498      0       1            0         0      0\n",
       "1119      0       0            0         0      1\n",
       "2144      0       0            0         1      0\n",
       "1134      0       0            0         0      1\n",
       "...     ...     ...          ...       ...    ...\n",
       "1877      0       0            0         0      0\n",
       "4         1       0            0         0      0\n",
       "17        1       0            0         0      0\n",
       "1323      1       0            0         1      0\n",
       "696       0       0            0         0      0\n",
       "\n",
       "[2166 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67        38\n",
      "           1       0.74      0.66      0.70        35\n",
      "           2       0.69      0.64      0.67        42\n",
      "           3       0.36      0.37      0.36        43\n",
      "           4       0.37      0.41      0.39        46\n",
      "\n",
      "   micro avg       0.53      0.55      0.54       204\n",
      "   macro avg       0.55      0.56      0.56       204\n",
      "weighted avg       0.54      0.55      0.55       204\n",
      " samples avg       0.46      0.46      0.46       204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = DecisionTreeClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69        38\n",
      "           1       1.00      0.60      0.75        35\n",
      "           2       0.97      0.74      0.84        42\n",
      "           3       0.68      0.35      0.46        43\n",
      "           4       0.86      0.41      0.56        46\n",
      "\n",
      "   micro avg       0.89      0.52      0.66       204\n",
      "   macro avg       0.89      0.53      0.66       204\n",
      "weighted avg       0.88      0.52      0.65       204\n",
      " samples avg       0.44      0.44      0.44       204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.55      0.70        38\n",
      "           1       0.95      0.51      0.67        35\n",
      "           2       0.90      0.67      0.77        42\n",
      "           3       0.65      0.30      0.41        43\n",
      "           4       0.69      0.20      0.31        46\n",
      "\n",
      "   micro avg       0.85      0.44      0.58       204\n",
      "   macro avg       0.83      0.45      0.57       204\n",
      "weighted avg       0.82      0.44      0.56       204\n",
      " samples avg       0.37      0.37      0.37       204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_jobs=12)\n",
    "\n",
    "etc.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = etc.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.61      0.72        38\n",
      "           1       0.92      0.69      0.79        35\n",
      "           2       0.92      0.83      0.88        42\n",
      "           3       0.69      0.58      0.63        43\n",
      "           4       0.64      0.78      0.71        46\n",
      "\n",
      "   micro avg       0.79      0.70      0.74       204\n",
      "   macro avg       0.81      0.70      0.74       204\n",
      "weighted avg       0.80      0.70      0.74       204\n",
      " samples avg       0.59      0.59      0.59       204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = KNeighborsClassifier(n_jobs=12)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amb1] *",
   "language": "python",
   "name": "conda-env-amb1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
