{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Classificadores Lineares\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Classificadores KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Classificadores Naive Nayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Classificadores Arvores de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "### Pipeline\n",
    "* Definir um workflow de análise\n",
    "* Criar um workflow que conecta transformadores e estimadores em uma sequência. \n",
    "* Cada etapa é realizada por uma classe, que são encapsuladas em uma classe maior e executadas sob controle de um pipeline\n",
    "### Salvando e Carregando modelos para arquivos\n",
    "* joblib\n",
    "### Busca por hiperparametros\n",
    "* Grid Search\n",
    "* Random Search\n",
    "### Validação Cruzada\n",
    "* Kfolds\n",
    "* Kfolds estratificados\n",
    "* LOOCV\n",
    "* repetição de divisão entre treino e teste\n",
    "### Escolha de características (Features)\n",
    "* kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No código abaixo está sendo feita a comparação entre 3 modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preparação dos dados para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['chd'], axis=1)\n",
    "y = df['chd']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X['famhist'] = le.fit_transform(X['famhist'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparação do score dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5319148936170213\n",
      "0.5319148936170213\n",
      "0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print(sgd.score(X_test, y_test))\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "print(tree.score(X_test, y_test))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Código complexo e dificil de manter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipelines auxiliam sistematizar a avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo um workflow com pipeline\n",
    "* A mesma análise anterior, porem, incluindo cada avaliação em um objeto pipe\n",
    "* Ao final um pipeline com outros pipes sao executados\n",
    "* Um pipe possui uma ou mais transformacoes,por exemplo, normalização, padronizaçõ, etc (que possue a funcao transform),  e por último um modelo de predição (que possui a função fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression pipeline test accuracy: 0.702\n",
      "KNN pipeline test accuracy: 0.660\n",
      "Decision Tree pipeline test accuracy: 0.553\n",
      "Classifier with best accuracy: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Construindo pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()), ('clf', LogisticRegression())])\n",
    "pipe_knn = Pipeline([('scl', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "# Lista de pipelines a serem executados\n",
    "pipelines = [pipe_lr, pipe_knn, pipe_dt]\n",
    "\n",
    "# Dicionário para facilitar identificacao\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'KNN', 2: 'Decision Tree'}\n",
    "\n",
    "# aplicando fit\n",
    "# Generaliza a execucao do fit de cada ultima funcao do pipe\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compara acurácia\n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "# para cada modelo treinado obtem val score\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "    # Descobre o melhor val.score e armazen em best_clf\n",
    "    if val.score(X_test, y_test) > best_acc:\n",
    "        best_acc = val.score(X_test, y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = idx\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando um modelo para um arquivo usando joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_pipeline.pkl']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save pipeline to file\n",
    "joblib.dump(best_pipe, 'best_pipeline.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando um modelo salvo em arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  4]\n",
      " [10  7]]\n"
     ]
    }
   ],
   "source": [
    "joblib_model= joblib.load('best_pipeline.pkl')\n",
    "\n",
    "y_pred = joblib_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca por hiperparametros\n",
    "* Hiperparametros sao as diversas parametrizações possíveis de um modelo de predição\n",
    "* Usando gridsearchCV: busca todas as combinações definidas de hiperparametros, e retorna combinação com o melhor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.679 (+/-0.048) for {'alpha': 1}\n",
      "0.683 (+/-0.053) for {'alpha': 10}\n",
      "0.666 (+/-0.065) for {'alpha': 100}\n",
      "0.666 (+/-0.067) for {'alpha': 1000}\n",
      "\n",
      "classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        30\n",
      "           1       0.64      0.41      0.50        17\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.68      0.64      0.64        47\n",
      "weighted avg       0.69      0.70      0.68        47\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.662 (+/-0.046) for {'alpha': 1}\n",
      "0.662 (+/-0.049) for {'alpha': 10}\n",
      "0.644 (+/-0.054) for {'alpha': 100}\n",
      "0.639 (+/-0.031) for {'alpha': 1000}\n",
      "\n",
      "classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        30\n",
      "           1       0.64      0.41      0.50        17\n",
      "\n",
      "    accuracy                           0.70        47\n",
      "   macro avg       0.68      0.64      0.64        47\n",
      "weighted avg       0.69      0.70      0.68        47\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'alpha': [1, 10, 100, 1000]},]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "        RidgeClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usando RandomizedSearchCV: busca um conjunto aleatório de combinações possíveis de hiperparametros, e retorna o modelo com o melhor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200, random_state=0)\n",
    "distributions = dict(penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(X_test, y_test)\n",
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "#### K-fold\n",
    "* fold: sub conjunto de dados para teste e treino\n",
    "* Sub conjuntos gerados movimentando um índice nos dados para definir o início e fim dos dados de treino\n",
    "* número K define quantidade de movimentações para gerar base de teste\n",
    "\n",
    "![Folds](https://www.researchgate.net/profile/Mingchao_Li/publication/331209203/figure/fig2/AS:728070977748994@1550597056956/K-fold-cross-validation-method.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Kfold iterando pelos índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7] [0 1]\n",
      "[0.3 0.4 0.5 0.6 0.7 0.8] [0.1 0.2]\n",
      "[0 1 4 5 6 7] [2 3]\n",
      "[0.1 0.2 0.5 0.6 0.7 0.8] [0.3 0.4]\n",
      "[0 1 2 3 6 7] [4 5]\n",
      "[0.1 0.2 0.3 0.4 0.7 0.8] [0.5 0.6]\n",
      "[0 1 2 3 4 5] [6 7]\n",
      "[0.1 0.2 0.3 0.4 0.5 0.6] [0.7 0.8]\n"
     ]
    }
   ],
   "source": [
    "# Amostra de dados\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "# Montando Folds\n",
    "kfold = KFold(4)\n",
    "\n",
    "\n",
    "for train, test in kfold.split(data):\n",
    "    print(train , test)\n",
    "    print(data[train] , data[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando acurácia de classificação com validação cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd  \\\n",
      "1  160    12.00  5.73      23.11     49    25.30    97.20   52    1   \n",
      "2  144     0.01  4.41      28.61     55    28.87     2.06   63    1   \n",
      "3  118     0.08  3.48      32.28     52    29.14     3.81   46    0   \n",
      "4  170     7.50  6.41      38.03     51    31.99    24.26   58    1   \n",
      "5  134    13.60  3.50      27.78     60    25.99    57.34   49    1   \n",
      "\n",
      "   famhist_label  \n",
      "1              1  \n",
      "2              0  \n",
      "3              1  \n",
      "4              1  \n",
      "5              1  \n"
     ]
    }
   ],
   "source": [
    "heart = pd.read_csv('SAheart.data')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "heart['famhist_label'] = le.fit_transform(heart['famhist'])\n",
    "heart.drop('famhist', axis=1, inplace=True)\n",
    "\n",
    "print(heart.head())\n",
    "\n",
    "\n",
    "X = heart[['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age','famhist_label']] \n",
    "y = heart[['chd']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 53.19%\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print(\"Acuracia: %.2f%%\" % (sgd.score(X_test, y_test)*100.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com Kfolds\n",
    "* Montando 10 folds para o mesmo classificador testado acima\n",
    "* cross_val_score aplica os folds e obtem o score do fit de cada sub conjunto\n",
    "* Ao final mostra a média das acurácias obtidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.57142857 0.28571429 0.26190476 0.83333333 0.30952381 0.58536585\n",
      " 0.63414634 0.7804878  0.58536585 0.6097561 ]\n",
      "Acuracia: 54.57%\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=100)\n",
    "model_kfold = SGDClassifier()\n",
    "results_kfold = cross_val_score(model_kfold, X_train, y_train, cv=kfold)\n",
    "print(\"scores: \", results_kfold) \n",
    "print(\"Acuracia: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds Stratificados\n",
    "\n",
    "* Utiliza folds estratificados: cada conjunto contendo aproximadamente a mesma proporção de labels de destino que os dados completos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.65714286 0.42857143 0.65217391 0.68115942 0.50724638 0.55882353]\n",
      "Accuracy: 58.09%\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=6, random_state=100)\n",
    "model_skfold = SGDClassifier()\n",
    "results_skfold = cross_val_score(model_skfold, X_train, y_train, cv=skfold)\n",
    "print(\"scores: \", results_skfold) \n",
    "print(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross-Validation (LOOCV)\n",
    "\n",
    "* Os Fold são definidos com tamanho 1 e K o número de observações\n",
    "\n",
    "* Essa variação é útil quando os dados de treinamento são de tamanho limitado e o número de parâmetros a serem testados não é alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.45%\n"
     ]
    }
   ],
   "source": [
    "loocv = LeaveOneOut()\n",
    "model_loocv = SGDClassifier()\n",
    "results_loocv = cross_val_score(model_loocv, X_train, y_train, cv=loocv)\n",
    "#print(\"scores: \", results_loocv) \n",
    "print(\"Accuracy: %.2f%%\" % (results_loocv.mean()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetição Aleatória de divisão entre treino e teste (Repeated Random Test-Train Splits)\n",
    "\n",
    "* Híbrido entre divisão tradicional de teste de trem e do método de validação cruzada de k Fold. \n",
    "\n",
    "* Nesta técnica, divisões entre treino e teste aleatórias são criadas nos dados da maneira definida pelo conjunto de testes de treinamento \n",
    "\n",
    "* Esse processo é repetidos várias vezes, assim como o método de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.624 0.376 0.328 0.672 0.672 0.432 0.624 0.52  0.736 0.56 ]\n",
      "Accuracy: 55.44% (13.02%)\n"
     ]
    }
   ],
   "source": [
    "kfold2 = ShuffleSplit(n_splits=10, test_size=0.30, random_state=100)\n",
    "model_shufflecv = SGDClassifier()\n",
    "results_4 = cross_val_score(model_shufflecv, X_train, y_train, cv=kfold2)\n",
    "print(\"scores: \", results_4) \n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_4.mean()*100.0, results_4.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.634\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__presort': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvio/.conda/envs/trackml6/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#pipe_knn = Pipeline([('scl', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "pipetree = Pipeline([('scl', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "#pipe = [pipe_knn, pipetre]\n",
    "pipe = [pipetree]\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "\n",
    "# grid search params\n",
    "grid_params = [{'clf__criterion': ['gini', 'entropy'],\n",
    "               'clf__presort': [True, False]}]\n",
    "#grid_params = [{'clf__criterion': ['gini', 'entropy'],\n",
    "#    'clf__min_samples_leaf': param_range,\n",
    "#    'clf__max_depth': param_range,\n",
    "#    'clf__min_samples_split': param_range[1:],\n",
    "#    'clf__presort': [True, False]}]\n",
    "\n",
    "# Construct grid search\n",
    "gs = GridSearchCV(estimator=pipetree,\n",
    "    param_grid=grid_params,\n",
    "    scoring='accuracy')\n",
    "\n",
    "# Fit using grid search\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo Features \n",
    "* Método kbest\n",
    "* Utiliza método chi quadrado para escolher melhor conjunto de features de acordo com o seguinte critério:\n",
    "* Realiza um teste estatístico usando qui-quadrado entre cada features e classe\n",
    "* O teste do qui-quadrado “elimina” features com maior probabilidade de serem independentes da classe e, portanto, irrelevantes para a classificação.\n",
    "\n",
    "Fonte: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print(X.shape)\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd  \\\n",
      "1  160    12.00  5.73      23.11     49    25.30    97.20   52    1   \n",
      "2  144     0.01  4.41      28.61     55    28.87     2.06   63    1   \n",
      "3  118     0.08  3.48      32.28     52    29.14     3.81   46    0   \n",
      "4  170     7.50  6.41      38.03     51    31.99    24.26   58    1   \n",
      "5  134    13.60  3.50      27.78     60    25.99    57.34   49    1   \n",
      "\n",
      "   famhist_label  \n",
      "1              1  \n",
      "2              0  \n",
      "3              1  \n",
      "4              1  \n",
      "5              1  \n",
      "(462, 9)\n",
      "(462, 3)\n"
     ]
    }
   ],
   "source": [
    "heart = pd.read_csv('SAheart.data')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "heart['famhist_label'] = le.fit_transform(heart['famhist'])\n",
    "heart.drop('famhist', axis=1, inplace=True)\n",
    "\n",
    "print(heart.head())\n",
    "\n",
    "\n",
    "X = heart[['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age','famhist_label']] \n",
    "y = heart[['chd']] \n",
    "\n",
    "print(X.shape)\n",
    "X_new = SelectKBest(chi2, k=3).fit_transform(X, y)\n",
    "print(X_new.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-trackml6]",
   "language": "python",
   "name": "conda-env-.conda-trackml6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
